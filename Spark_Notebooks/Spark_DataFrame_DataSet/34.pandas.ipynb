{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1042dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas-on-Spark DataFrame:\n",
      "   id     name  age  salary\n",
      "0   1    Alice   25   50000\n",
      "1   2      Bob   30   60000\n",
      "2   3  Charlie   35   75000\n",
      "3   4    David   40   80000\n",
      "4   5     Emma   45  120000\n",
      "\n",
      "Average Age: 35.0\n",
      "\n",
      "Summary Statistics:\n",
      "             id        age        salary\n",
      "count  5.000000   5.000000       5.00000\n",
      "mean   3.000000  35.000000   77000.00000\n",
      "std    1.581139   7.905694   26832.81573\n",
      "min    1.000000  25.000000   50000.00000\n",
      "25%    2.000000  30.000000   60000.00000\n",
      "50%    3.000000  35.000000   75000.00000\n",
      "75%    4.000000  40.000000   80000.00000\n",
      "max    5.000000  45.000000  120000.00000\n",
      "\n",
      "DataFrame after Salary Increment:\n",
      "   id     name  age  salary  salary_after_increment\n",
      "0   1    Alice   25   50000                 55000.0\n",
      "1   2      Bob   30   60000                 66000.0\n",
      "2   3  Charlie   35   75000                 82500.0\n",
      "3   4    David   40   80000                 88000.0\n",
      "4   5     Emma   45  120000                132000.0\n",
      "\n",
      "Filtered DataFrame (age > 30):\n",
      "   id     name  age  salary  salary_after_increment\n",
      "2   3  Charlie   35   75000                 82500.0\n",
      "3   4    David   40   80000                 88000.0\n",
      "4   5     Emma   45  120000                132000.0\n",
      "\n",
      "Converted Spark DataFrame (with index):\n",
      "+-----+---+-------+---+------+----------------------+\n",
      "|index| id|   name|age|salary|salary_after_increment|\n",
      "+-----+---+-------+---+------+----------------------+\n",
      "|    0|  1|  Alice| 25| 50000|     55000.00000000001|\n",
      "|    1|  2|    Bob| 30| 60000|               66000.0|\n",
      "|    2|  3|Charlie| 35| 75000|               82500.0|\n",
      "|    3|  4|  David| 40| 80000|               88000.0|\n",
      "|    4|  5|   Emma| 45|120000|              132000.0|\n",
      "+-----+---+-------+---+------+----------------------+\n",
      "\n",
      "\n",
      "Reconverted Pandas-on-Spark DataFrame:\n",
      "   index  id     name  age  salary  salary_after_increment\n",
      "0      0   1    Alice   25   50000                 55000.0\n",
      "1      1   2      Bob   30   60000                 66000.0\n",
      "2      2   3  Charlie   35   75000                 82500.0\n",
      "3      3   4    David   40   80000                 88000.0\n",
      "4      4   5     Emma   45  120000                132000.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "os.environ['PYARROW_IGNORE_TIMEZONE'] = '1'\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pandas API on Spark\") \\\n",
    "    .config(\"spark.sql.ansi.enabled\", \"false\") \\\n",
    "    .config(\"spark.executorEnv.PYARROW_IGNORE_TIMEZONE\", \"1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. Create a pandas-on-Spark DataFrame\n",
    "ps_df = ps.DataFrame({\n",
    "    \"id\": [1, 2, 3, 4, 5],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Emma\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"salary\": [50000, 60000, 75000, 80000, 120000]\n",
    "})\n",
    "\n",
    "print(\"Pandas-on-Spark DataFrame:\")\n",
    "print(ps_df)\n",
    "\n",
    "# 2. Perform Pandas-style operations on Spark\n",
    "print(\"\\nAverage Age:\", ps_df[\"age\"].mean())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(ps_df.describe())\n",
    "\n",
    "# 3. Apply a function: Add a new column with salary increment\n",
    "ps_df[\"salary_after_increment\"] = ps_df[\"salary\"] * 1.1\n",
    "print(\"\\nDataFrame after Salary Increment:\")\n",
    "print(ps_df)\n",
    "\n",
    "# 4. Filtering (Similar to Pandas)\n",
    "filtered_ps_df = ps_df[ps_df[\"age\"] > 30]\n",
    "print(\"\\nFiltered DataFrame (age > 30):\")\n",
    "print(filtered_ps_df)\n",
    "\n",
    "# 5. Convert Pandas-on-Spark DataFrame to Spark DataFrame\n",
    "# Opção A: Preservar o índice como coluna\n",
    "spark_df = ps_df.to_spark(index_col=\"index\")\n",
    "print(\"\\nConverted Spark DataFrame (with index):\")\n",
    "spark_df.show()\n",
    "\n",
    "# 6. Convert Spark DataFrame back to Pandas-on-Spark DataFrame\n",
    "ps_df_from_spark = ps.DataFrame(spark_df)\n",
    "print(\"\\nReconverted Pandas-on-Spark DataFrame:\")\n",
    "print(ps_df_from_spark)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059fdf7-fd2d-4e82-9706-93e48209f5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
